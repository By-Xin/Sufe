# 第三章：多元线性回归模型

## 3.1 多元线性回归模型（概述）

### 一、 模型形式

线性回归模型的一般形式为：

$$Y=\beta_0 + \beta_1 X_1 + \cdots +\beta_k X_k +\mu $$

其非随机表达式为：

$$E(Y|X_1,...,X_k)=\beta_0+\beta_0 + \beta_1 X_1 + \cdots +\beta_k X_k $$

**说明：**

- 线性在这里指的是参数$\beta$是线性的；例如$Y=\beta_0 + \beta_1 X_1X_2$ 是一个线性模型，而$Y=\beta_0+\beta_1^2 X_1$不是。
- 在计量中，理想情况下要增加对$X$的外生性假定（源自于系统外部），该假定的具体数学讨论将在第四章展开。
- 在本课程中，不对$X$的随机性进行要求

$\square$

在给出总体的一个样本后，即可对该模型进行估计，近似代表未知的总体回归函数，具体表示为：

$$Y=\hat \beta_0 + \hat \beta_1 X_1 + \cdots +\hat\beta_k X_k +e $$

其中称$e$为残差项或余项(residual)，可以认为是总体回归函数中随机干扰项$\mu$的近似。

$\square$

### 二、 多元线性回归模型的基本假设

- 模型是正确设定的；
- 解释变量具有变异性，无完全多重共线性（严格线性相关）；
- 随机干扰项条件零均值：$E(\mu|X)=0$ （否则说明模型设置有问题）
- 随机干扰项条件同方差，且不相关：$Cov(\mu|X)=\sigma^2 I$ （各项的为观测部分对于每个观测样本的影响都是一样的（即抽样是随机的））
- *随机干扰项满足正态分布（该假设并不是必要的，假设的主要目的是便于后续的模型检验和统计推断）*

## 3.2 多元线性回归模型的参数估计

主要任务：估计$\hat\beta_j$,$\hat\sigma$

### 一、 普通最小二乘(OLS)

估计目的：使得RSS最小，即

$$\arg \min _{\beta} Q(\beta)=\sum_{i=1}^n e_i^2$$

正规方程：
$$(X^\prime X)^{-1}\hat\beta=X^\prime Y$$

估计结果：

$$\hat \beta = (X^TX)^{-1}X^TY$$

$$\hat\sigma^2 = \frac{e^Te}{n-k-1}$$

其中$k$为参数个数。

### 二、 极大似然估计 (MLE)

极大似然必须已知$Y$的分布（当G-M条件不适用时可以用MLE）

估计结果：

$$\hat \beta _{MLE}=(X^TX)^{-1}X^TY$$

$$\hat\sigma^2_{MLE} = \frac{e^Te}{n}$$

注意：$\hat\sigma^2_{MLE}$是有偏的

### 三、 拟合优度

#### 1. 可决系数$R^2$

- 总离差平方和（总的变动情况）：$TSS=\sum (Y_i-\bar Y)^2 = \sum y_i^2$
- 回归平方和（模型可解释部分）：$ESS = \sum(\hat Y_i-\bar Y)^2 = \sum \hat y_i^2$
- 残差平方和（模型无法解释部分）：$RSS = \sum( Y_i-\hat Y_i)^2 = \sum e_i^2$

可证明恒有：

$$TSS = ESS + RSS $$

故可用模型可解释部分的占比作为模型拟合优度的衡量指标：

$$R^2 = \frac{ESS}{TSS} = 1 - \frac{RSS}{TSS}$$

故$R^2$越接近1，模型拟合优度越高。

#### 2. 调整的可决系数 $\bar R^2$

在实证中可以发现，如果解释变量增加，$R^2$定是不减的（往往增大），但模型的拟合优度并不是变量数越多越好，因此就变量个数进行惩罚，有：

$$\bar R^2 = 1- \frac{RSS/(n-k-1)}{TSS/(n-1)}$$

$\square$

*说明：在实证中，$R^2$的取值多少为优并没有统一的标准，有时为了其更好的实证含义与解释效果，也可以牺牲部分的$R^2$*

## 3.3 模型的统计性质与统计检验

### 一、参数估计量的统计性质

#### 1. 线性性

参数估计量是被解释变量观测值$Y_i$的线性组合：
$$\hat \beta = (X^TX)^{-1}X^TY = CY$$

其中$C$仅仅与$X$有关，而在本模型中认为$X$是完全已知的（给定的常数）

#### 2. 无偏性

$$E(\hat\beta|X)=\beta$$

证明的过程中利用了假设：$E(\mu|X)=0$

#### 3. 有效性（最小方差）(G-M定理)

$$var(\hat\beta|X) = \sigma^2(X^T X)^{-1}$$

证明的过程中利用到性质：
$$\hat\beta = (X^TX)^{-1}X^TY = (X^TX)^{-1}X^T(X\beta+\mu)\\=(X^TX)^{-1}X^TX\beta+(X^TX)^{-1}X^T\mu\\ = \beta + (X^TX)^{-1}X^T\mu$$
及
$$E(\mu^T\mu|X)=\sigma^2 I$$

$\square$

此外在大样本下，参数估计量还是一致的、渐进有效的。

### 二、变量显著性检验

#### 1. 参数估计量的概率分布

若给定随机干扰项是服从正态分布的，则有：
$$Y|X\sim N(X\beta,\sigma^2I_n)$$
故有：
$$\hat\beta|X\sim N(\beta,\sigma^2(X^TX)^{-1})$$

$\square$

在大样本下，只要样本具有独立同方差的随机分布性质，可以不再对分布进行要求，由CLT定理，其渐进分布同样服从上述表达形式。

#### 2. 变量显著性检验 (t-test)

$$H_0:\beta_j=0, ~v.s. ~H_1:\beta_j\neq 0$$

$$t=\frac{\hat\beta_j-\beta_j}{S_{\hat\beta_j}}=\frac{\hat\beta_j-\beta_j}{\sqrt{c_{jj}\hat\sigma^2}}\sim t(n-k-1)$$

**说明：**

**1. 建模时的截距项$\beta_0$**

- 该项是应当尽量保留的（而不是过度依赖于t检验的检验结果），因为该项具有较强的计量意义。
- 其表示$y$不能由$X$解释的、相对稳定的非随机部分，而$\mu$则表示的是非确定性，两者含义不同，故不能随意丢弃。

**2. 显著性的讨论**

- 经常在实证中会遇到各个变量的*t*值相差较大，有的显著性好，有的则不太显著。
- 没有绝对的显著性水平，**关键仍然是考量其在经济（实证）关系上是否对被解释变量有影响**。
- 有一些解释变量的经济显著性很大（economic significance），也就是其参数估计的估计值较大，但统计显著性较小甚至不显著。有时这也可能是由于多重共线性等其他问题造成的。
- 因此，不要简单的剔除经济含义较强而显著性较弱的变量。
- 在多元回归中，还要综合通过*F*检验考察具有明确经济关联性的若干解释变量联合起来是否对解释变量有显著影响。

### 三、参数的置信区间

在$1-\alpha$下$\beta_j$的置信区间为：

$$(\hat\beta_j-t_{\alpha/2}S_{\hat\beta_j},\hat\beta_j+t_{\alpha/2}S_{\hat\beta_j})$$

$\square$

在实证中，我们希望置信度越大越好，置信区间越小越好。因此通常的改良方式：

- 增大样本量$n$
- 提高模型的拟合优度
- 提高样本观测的分散程度

### 四、方程的显著性检验 (F-test)

检验目的：模型中所有的解释变量与被解释变量之间的线性关系在总体上是否显著成立。

$$H_0:\beta_1=\dots=\beta_k=0~~~H_1: 不全为0~$$

$$F = \frac{ESS/k}{RSS/(n-k-1 )}\sim F(k,n-k-1)$$

在一元情况下，*F*与*t*检验是一致的。

$\square$

通过数学推导，还可以发现：

$$F=\frac{k}{n-k-1}\frac{R^2}{1-R^2}$$

即$F\propto R^2$，因此F检验也等价于检验$H_0:R^2=0$

此外由$\bar R^2$与$F$的关系中，即使$\bar R^2$较小，有时其F检验的置信度仍然达到了95%，因此在实证中不应当对$\bar R^2$过于苛求，更重要的是要考察其经济关系是否合理，F检验是否通过。

$\square$

*补充：通常而言$\alpha$取5%；但在一些宏观问题中，有时$\alpha$可取10%*

## 3.4 多元线性回归模型的预测

## 3.5 非线性模型转化为线性模型

## 3.6 含有虚拟变量（作为解释变量）的多元线性回归模型

### 一、虚拟变量的引入

虚拟变量通常为一个0-1变量，表示是否符合某情况的情形。

#### 1. 加法方式

将“是否”状态的差异体现在截距项（即固有属性上）

例如：

$$Y_i = \beta_0 + \beta_1 X_i+ \beta_2 D$$

这时如果$\beta_2$显著，则该变量“是否”之间将导致两回归结果相差一个截距项$\hat\beta_2$（平移关系）。

此外要注意虚拟变量陷阱，例如若某教育程度变量要考虑三个水平：高中以下、高中、大学及以上，则需要引入两个虚拟变量：
$$D_1=1_{\{高中学历\}},D_2=1_{\{大学及以上学历\}}$$

#### 2. 乘法方式

变量“是否”的影响也可以作用在斜率的变化上，例如：

$$C_i=\beta_0+\beta_1X_i+\beta_2D_iX_i+\mu_i$$

$\square$

当然，也可以同时引入加法和乘法方式进行考量。

### 二、 虚拟变量的设置原则

- 若有m个定型变量，则引入m-1个虚拟变量（虚拟变量陷阱）
- 对于一些定型定序变量，当定性因素较多时，理论上应该对每个状态都设置一个相应的哑变量，但这对于一些调查问卷、量表的处理将引入过多变量。因此一种不严谨的做法是使用赋值法进行考量，即认为定序变量就是其相应数值（这相当于施加了一定约束）。

## 3.7 受约束回归

### 一、模型参数的线性约束

问题说明：有时模型的参数是具有一定约束限制条件的，例如一些经济公式方程中常有:$\beta_1+\beta_2=1$等。我们在进行回归时，并没有将这一约束条件进行特殊处理，只是通过经济数据进行了简单的回归分析。但是理论上，只要经济数据正确，那么由数据得到的模型就应当符合一些约束条件（例如回归的结果是$\hat\beta_1=0.234,\hat\beta_2=0.761）$因而就需要检验这些回归参数在统计意义上到底是否符合这一约束条件（经济规律）。

检验思路：

- 首先可以不加约束地对于模型进行回归，记为模型U(unrestricted)
- 然后将约束条件代入到无约束模型中，得到一个显式的，包含约束条件的含约束模型再次回归，记为R(restricted)
- 通常条件下，增加约束条件会显著增大模型的RSS；但如果约束条件是一直成立的，那么模型U在数值上则应当与R差不多，即不应当引起显著的RSS的变化

检验统计量：

$$F=\frac{(RSS_R-RSS_U)/(k_U-k_R)}{RSS_U/
(n-k_U-1)}\sim F(k_U-k_R,n-k_U-1)$$

其中k为各自模型中解释变量的个数。
